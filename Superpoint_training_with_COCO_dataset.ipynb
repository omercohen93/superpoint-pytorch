{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Superpoint_training_with_COCO_dataset.ipynb","provenance":[],"collapsed_sections":["2WXfmcIKS2As","es_Y7Yj7TpI2","audZzq95V2yT","_Q4unyskW7nu","jBIPot_UiK5f"],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.8"}},"cells":[{"cell_type":"markdown","metadata":{"id":"-PiXOVyuR673"},"source":["# Setup"]},{"cell_type":"code","metadata":{"id":"QROgw9F1SVGO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614958830410,"user_tz":-120,"elapsed":153710,"user":{"displayName":"תקוה כהן","photoUrl":"","userId":"01741536388990615411"}},"outputId":"66b6c130-2fd9-4f11-d747-d13fbfaa4648"},"source":["%pip install kornia==0.4.0\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import cv2\n","import math \n","import torch\n","from torchvision import datasets, transforms\n","from torch import nn, optim\n","import torch.nn.functional as F\n","import matplotlib.pyplot as plt\n","import kornia as K\n","import time"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting kornia==0.4.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fb/18/f767c3f8c28945f0ae5d5db34517f56897cece8175389f54cb8ffacdab99/kornia-0.4.0-py2.py3-none-any.whl (195kB)\n","\u001b[K     |████████████████████████████████| 204kB 17.2MB/s \n","\u001b[?25hCollecting torch<1.7.0,>=1.6.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5d/5e/35140615fc1f925023f489e71086a9ecc188053d263d3594237281284d82/torch-1.6.0-cp37-cp37m-manylinux1_x86_64.whl (748.8MB)\n","\u001b[K     |████████████████████████████████| 748.8MB 23kB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from kornia==0.4.0) (1.19.5)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch<1.7.0,>=1.6.0->kornia==0.4.0) (0.16.0)\n","\u001b[31mERROR: torchvision 0.8.2+cu101 has requirement torch==1.7.1, but you'll have torch 1.6.0 which is incompatible.\u001b[0m\n","Installing collected packages: torch, kornia\n","  Found existing installation: torch 1.7.1+cu101\n","    Uninstalling torch-1.7.1+cu101:\n","      Successfully uninstalled torch-1.7.1+cu101\n","Successfully installed kornia-0.4.0 torch-1.6.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"GZv-fvGtSk8x"},"source":["## Mount drive"]},{"cell_type":"code","metadata":{"id":"iTEDRFcbSlzV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614958899806,"user_tz":-120,"elapsed":223096,"user":{"displayName":"תקוה כהן","photoUrl":"","userId":"01741536388990615411"}},"outputId":"06710d1f-2090-47b4-e51c-eeffb46581ad"},"source":["your_path = ''\r\n","from google.colab import drive\r\n","drive.mount('/content/gdrive')\r\n","path = '/content/gdrive/My Drive/'+your_path\r\n","import sys\r\n","sys.path.append(path)\r\n","from utils.points import cords_to_map"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"1EfKNOPTTCX9"},"source":["## GPU"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vLsTtFwBS_WG","executionInfo":{"status":"ok","timestamp":1614958899807,"user_tz":-120,"elapsed":223091,"user":{"displayName":"תקוה כהן","photoUrl":"","userId":"01741536388990615411"}},"outputId":"d134065b-23ae-47c3-8434-af5139c371bd"},"source":["print(torch.__version__)\n","train_on_gpu = torch.cuda.is_available()\n","\n","if not train_on_gpu:\n","  DEVICE = 'cpu'\n","  print('CUDA is not available.  Training on CPU ...')\n","else:\n","  DEVICE = 'cuda'\n","  print('CUDA is available!  Training on GPU ...')\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1.6.0\n","CUDA is available!  Training on GPU ...\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"cV77yN94TOdn"},"source":["# DATA"]},{"cell_type":"markdown","metadata":{"id":"2WXfmcIKS2As"},"source":["## Define transformatiom"]},{"cell_type":"code","metadata":{"id":"fjnZ_rPKaRKR"},"source":["from datasets.utils.transforms import ColorJitter, ToGray, Rescale,ToTensor, get_twin"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"es_Y7Yj7TpI2"},"source":["## Dataset model"]},{"cell_type":"code","metadata":{"id":"XmocRKD4TV9v"},"source":["from datasets.COCO.COCO_model import COCO_dataset\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QLd0aweBU-MC"},"source":["## Generate dataset and dataloader"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"QUb6fXeyVGdm","executionInfo":{"status":"ok","timestamp":1614958903218,"user_tz":-120,"elapsed":226488,"user":{"displayName":"תקוה כהן","photoUrl":"","userId":"01741536388990615411"}},"outputId":"df6c53ad-f220-41ec-97d9-45efb8856f35"},"source":["transform = transforms.Compose([Rescale((240,320)),\n","                                ColorJitter(), \n","                                ToGray(),\n","                                ToTensor()]) \n","\n","dataset = COCO_dataset(path+'/datasets/COCO/labeled_coco.csv',\n","                                  path+'/datasets/COCO/val2017/', \n","                                  transform=transform, \n","                                  landmark_bool=True)\n","dataloader = torch.utils.data.DataLoader(dataset, batch_size=5, shuffle=True)\n","'''\n","print(len(dataset))\n","print(len(dataloader))\n","for iter, (im,label) in enumerate(dataloader):\n","  print('ok')\n","  if iter>2:\n","    break\n","'''\n","\n","  "],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"\\nprint(len(dataset))\\nprint(len(dataloader))\\nfor iter, (im,label) in enumerate(dataloader):\\n  print('ok')\\n  if iter>2:\\n    break\\n\""]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"VOlf25b1R5HQ"},"source":["## Test model"]},{"cell_type":"markdown","metadata":{"id":"audZzq95V2yT"},"source":["### plot function"]},{"cell_type":"code","metadata":{"id":"KRfG9AjiVkj5"},"source":["from utils.plot import plot_imgs\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_Q4unyskW7nu"},"source":["### test"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":67},"id":"hxMmcv06W59h","executionInfo":{"status":"ok","timestamp":1614958903229,"user_tz":-120,"elapsed":226483,"user":{"displayName":"תקוה כהן","photoUrl":"","userId":"01741536388990615411"}},"outputId":"2775633d-c16c-46ab-aea7-17516f25e2cf"},"source":["'''for iter, (im, label) in enumerate(dataloader):\n","  label = label.type(torch.double)\n","  label = label.unsqueeze(1)\n","  imgs= K.tensor_to_image(im)\n","  size = im.size()\n","  map = cords_to_map(label, size, device=False)\n","  im_map = K.tensor_to_image(map)\n","  if iter%10==0:\n","    print('iteration {}/{} is running'.format(iter,len(dataloader)))\n","  plot_imgs(imgs, label=label)\n","  plot_imgs(im_map)\n","  if iter>0:\n","    break\n","'''"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"for iter, (im, label) in enumerate(dataloader):\\n  label = label.type(torch.double)\\n  label = label.unsqueeze(1)\\n  imgs= K.tensor_to_image(im)\\n  size = im.size()\\n  map = cords_to_map(label, size, device=False)\\n  im_map = K.tensor_to_image(map)\\n  if iter%10==0:\\n    print('iteration {}/{} is running'.format(iter,len(dataloader)))\\n  plot_imgs(imgs, label=label)\\n  plot_imgs(im_map)\\n  if iter>0:\\n    break\\n\""]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"jBIPot_UiK5f"},"source":["# Net architecture"]},{"cell_type":"markdown","metadata":{"id":"xQwW0N-mi0Du"},"source":["## Superpoint model"]},{"cell_type":"code","metadata":{"id":"rBCJC3jbif_q"},"source":["from models.superpoint import SuperPointNet"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IP8lKGmjja9X"},"source":["## functions for Loss calculations"]},{"cell_type":"code","metadata":{"id":"WCsM6CjfjZYi"},"source":["from models.utils import detector_loss, descriptor_loss\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OZ0eeaexl-0X"},"source":["# Training Superpoint on COCO"]},{"cell_type":"markdown","metadata":{"id":"nAGM9utB1pyc"},"source":["## Train function"]},{"cell_type":"code","metadata":{"id":"PModR5u1l-Lf"},"source":["def train_coco_magic(dataloader, net, save_path, filename, lr=0.001):\n","  t_0 = time.time()\n","  optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n","  DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n","  net.to(DEVICE)\n","  model.train()\n","  N_epoch = 4\n","  for e in range(N_epoch):\n","    for iter, (im, label) in enumerate(dataloader):\n","      optimizer.zero_grad()\n","      im = im.to(DEVICE).type(torch.float)\n","      label = label.to(DEVICE)\n","    \n","      #get twin im and homography\n","      twin_im, H = get_twin(im)\n","      if len(H.size()) < 3:\n","            H = H.unsqueeze(0)\n","      H_invert = torch.inverse(H)\n","      \n","      #go through model\n","      chi_points, desc = net(im)\n","      twin_chi_points, twin_desc = net(twin_im)\n","      #get map label\n","      label = label.type(torch.double)\n","      size = im.size()\n","      map = cords_to_map(label, size)\n","      map[map<0.01] = 0\n","      map[:,:,0:5,0] = 0\n","      map[:,:,:,0:7] = 0\n","      map[:,:,-5:,:] = 0\n","      map[:,:,:,-7:] = 0      \n","\n","      #get twin map and valid mask\n","      twin_map = map.type(torch.float)  \n","      twin_map = K.warp_perspective(twin_map, H, dsize=(im.size(2), im.size(3)))\n","      valid_mask = torch.ones_like(im, dtype=torch.float32).to(DEVICE)\n","      valid_mask = K.warp_perspective(valid_mask, H, dsize=(im.size(2), im.size(3)))\n","\n","        \n","      #loss\n","      detector_loss_1 = detector_loss(map, chi_points)\n","      detector_loss_2 = detector_loss(twin_map, twin_chi_points)\n","      desc_loss = descriptor_loss(desc, twin_desc, H, H_invert, valid_mask)\n","      loss = detector_loss_1 + detector_loss_2 + 0.0001*desc_loss\n","      \n","      #optimize\n","      loss.backward()\n","      optimizer.step()\n","      \n","      \n","      if iter%10==0:\n","        print('iteration {}/{} is running'.format(e*len(dataloader)+iter,N_epoch*len(dataloader)))\n","        print('loss is:',loss.item())\n","      if iter%50==0:\n","        t_c = time.time()\n","        minute = (t_c-t_0)/60\n","        print('saving weights from iteration {} with loss {}, {} minutes pased'.format(e*len(dataloader)+iter,loss.item(),int(minute)))\n","        print('detector loss 1: {}, detector loss 2: {}, descriptor loss: {}'.format(detector_loss_1,detector_loss_2,desc_loss))\n","        torch.save(model.state_dict(), save_path+filename)\n","  # Save weights\n","  torch.save(model.state_dict(), save_path+filename)\n","  t_f = time.time()\n","  hours = (t_f-t_0)/3600\n","  print('finished in {} hours'.format(hours))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0ziQBW1vScba"},"source":["## Run"]},{"cell_type":"code","metadata":{"id":"j1USCOAGSd6q"},"source":["#tensorflow\n","from torch.utils.tensorboard import SummaryWriter\n","from datetime import datetime\n","import os \n","\n","%load_ext tensorboard\n","\n","logs_base_dir = 'logs'\n","os.makedirs(logs_base_dir, exist_ok=True)\n","\n","\n","\n","dataloader = torch.utils.data.DataLoader(dataset, batch_size=3, shuffle=True)\n","model = SuperPointNet(superpoint_bool=True)\n","weights_path = path+'/weights/magic_coco_weights.pth'\n","model.load_state_dict(torch.load(weights_path,\n","                               map_location=lambda storage, loc: storage))\n","\n","\n","\n","train_coco_magic(dataloader, model, path, '/weights/super_coco_weights_test.pth')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9XSBl7vMWvRP"},"source":["#writer_magic.flush()\n","%tensorboard --logdir 'logs'"],"execution_count":null,"outputs":[]}]}